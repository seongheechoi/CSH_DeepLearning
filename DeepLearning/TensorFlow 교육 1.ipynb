{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af9ce81",
   "metadata": {},
   "source": [
    "# 1. Tensorflow 2.0 기본"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ad798",
   "metadata": {},
   "source": [
    "## 1.1 Eager execution(즉시 실행)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9b0ba",
   "metadata": {},
   "source": [
    "텐서플로의 즉시 실행은 그래프를 생성하지 않고 함수를 바로 실행하는 명령형 프로그래밍 환경.\n",
    "나중에 실행하기 위해 계산가능한 그래프를 생성하는 대신에 계산값을 즉시 알려주는 연산\n",
    "이러한 기능은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d585e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9182ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ee00f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[11]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2]]\n",
    "y = [[3],[4]]\n",
    "m = tf.matmul(x,y)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48c0bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4]]) #상수는 내부값을 못바꾼다\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72ce34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅 지원\n",
    "b = tf.add(a, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de17bea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 연산자 오버로딩 지원\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f710272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524adb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "c = np.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1f64e",
   "metadata": {},
   "source": [
    "## 그래디언트 계산하기\n",
    "자동 미분은 인공신경망 훈련을 위한 역전파와 같은 기계학습 알고리즘을 구현하는데 유용. 즉시 실행을 사용하는 동안에는, 나중에 그래디언트를 계산하는 연산을 추적하기 위해 tf.GradientTape을 사용\n",
    "즉시 실행중에 그래디언트를 계산하고 모델 훈련에 이용하기 위해서 tf.GradientTape 사용할 수 있다. 특히 복잡하고 반복적인 훈련인 경우에 더 유용\n",
    "매번 실행될 때 서로 다른 연산이 수행될 수 있기 때문에 모든 정방향 연산은 tape에 기록된다. 그 다음 tape을 거꾸로 돌려 그래디언트를 계산후 tape을 폐기한다. 특정한 tf.GradientTape은 오직 하나의 그래디언트만을 계산할 수 있고 부가적인 호출은 실행 중 에러를 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085b0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w\n",
    "    \n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d131a",
   "metadata": {},
   "source": [
    "## 모델 훈련\n",
    "다음 예는 표준 MNIST 손글씨 분류를 위한 다층 모델을 생성, 즉시 실행 환경에서 훈련 가능한 그래프를 생성하기 위한 옵티마이저와 층 API를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f40e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 가져오기 및 포맷 맞추기\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32), tf.cast(mnist_labels, tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61eb77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,[3,3],activation='relu',\n",
    "                          input_shape=(None,None,1)),\n",
    "    tf.keras.layers.Conv2D(16,[3,3],activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e806f7ac",
   "metadata": {},
   "source": [
    "즉시 실행에서는 훈련을 하지 않아도 모델을 사용하고 결과를 점검할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "100e48e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로짓:  [[-0.02189998 -0.02657841 -0.00553481 -0.02905848 -0.01789952  0.00336728\n",
      "   0.03077359 -0.04671326 -0.0267408  -0.03950467]]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in dataset.take(1):\n",
    "    print('로짓: ', mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c477c08",
   "metadata": {},
   "source": [
    "케라스 모델은 자체적인 훈련 메서드(fit)을 포함하고 있지만 때로는 좀 더 수정할 필요가 있다. 다음은 즉시 실행을 활용한 반복적인 훈련의 예이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb2bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33b2ddce",
   "metadata": {},
   "source": [
    "## 변수와 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7f20b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 손실:69.980\n",
      "스텝 000에서 손실: 67.226\n",
      "스텝 020에서 손실: 30.320\n",
      "스텝 040에서 손실: 13.987\n",
      "스텝 060에서 손실: 6.758\n",
      "스텝 080에서 손실: 3.559\n",
      "스텝 100에서 손실: 2.143\n",
      "스텝 120에서 손실: 1.516\n",
      "스텝 140에서 손실: 1.238\n",
      "스텝 160에서 손실: 1.115\n",
      "스텝 180에서 손실: 1.061\n",
      "스텝 200에서 손실: 1.037\n",
      "스텝 220에서 손실: 1.026\n",
      "스텝 240에서 손실: 1.021\n",
      "스텝 260에서 손실: 1.019\n",
      "스텝 280에서 손실: 1.018\n",
      "스텝 300에서 손실: 1.018\n",
      "스텝 320에서 손실: 1.018\n",
      "스텝 340에서 손실: 1.018\n",
      "스텝 360에서 손실: 1.018\n",
      "스텝 380에서 손실: 1.018\n",
      "스텝 400에서 손실: 1.018\n",
      "스텝 420에서 손실: 1.018\n",
      "스텝 440에서 손실: 1.018\n",
      "스텝 460에서 손실: 1.018\n",
      "스텝 480에서 손실: 1.018\n",
      "스텝 500에서 손실: 1.018\n",
      "스텝 520에서 손실: 1.018\n",
      "스텝 540에서 손실: 1.018\n",
      "스텝 560에서 손실: 1.018\n",
      "스텝 580에서 손실: 1.018\n",
      "스텝 600에서 손실: 1.018\n",
      "스텝 620에서 손실: 1.018\n",
      "스텝 640에서 손실: 1.018\n",
      "스텝 660에서 손실: 1.018\n",
      "스텝 680에서 손실: 1.018\n",
      "스텝 700에서 손실: 1.018\n",
      "스텝 720에서 손실: 1.018\n",
      "스텝 740에서 손실: 1.018\n",
      "스텝 760에서 손실: 1.018\n",
      "스텝 780에서 손실: 1.018\n",
      "스텝 800에서 손실: 1.018\n",
      "스텝 820에서 손실: 1.018\n",
      "스텝 840에서 손실: 1.018\n",
      "스텝 860에서 손실: 1.018\n",
      "스텝 880에서 손실: 1.018\n",
      "스텝 900에서 손실: 1.018\n",
      "스텝 920에서 손실: 1.018\n",
      "스텝 940에서 손실: 1.018\n",
      "스텝 960에서 손실: 1.018\n",
      "스텝 980에서 손실: 1.018\n",
      "최종 손실: 1.018\n",
      "W = 3.01543927192688, B = 1.9726004600524902\n"
     ]
    }
   ],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.W = tf.Variable(5., name='weight')\n",
    "        self.B = tf.Variable(10., name='bias')\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.W + self.B\n",
    "    \n",
    "# 약 3 * 2 + 2개의 점으로 구성된 실험데이터\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
    "noise = tf.random.normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# 최적화 손실함수\n",
    "def loss(model, inputs, targets):\n",
    "    error = model(inputs) - targets\n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, [model.W, model.B])\n",
    "\n",
    "# 정의:\n",
    "# 1. 모델\n",
    "# 2. 모델 파라미터에 대한 손실 함수의 미분\n",
    "# 3. 미분에 기초한변수 업데이트 전략\n",
    "\n",
    "model = Model()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "print(\"초기 손실:{:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "# 반복훈련\n",
    "for i in range(1000):\n",
    "    grads = grad(model, training_inputs, training_outputs)\n",
    "    optimizer.apply_gradients(zip(grads, [model.W, model.B]))\n",
    "    if i % 20 == 0:\n",
    "        print(\"스텝 {:03d}에서 손실: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "print(\"최종 손실: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ad0f9",
   "metadata": {},
   "source": [
    "변수는 객체, 즉시 실행에서는 변수는 그 객체의 마지막 참조가 제거될 때까지 유지되고 그 이후 삭제됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9a8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d654e0",
   "metadata": {},
   "source": [
    "## 1.2 tensor 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f0788",
   "metadata": {},
   "source": [
    "스칼라 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828cebc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cd988",
   "metadata": {},
   "source": [
    "1차원 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adade76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bc28c",
   "metadata": {},
   "source": [
    "2차원 행렬, 랭크2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98bea9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_2_tensor = tf.constant([[1,2],[3,4],[5,6]])\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cab1f2",
   "metadata": {},
   "source": [
    "3차원 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f0c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[17 18 19 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_3_tensor = tf.constant([[[1,2,3,4],[5,6,7,8]],[[9,10,11,12],[13,14,15,16]],[[17,18,19,20],[21,22,23,24]]])\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "935bdc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[4.,5.],[10.,1.]])\n",
    "\n",
    "print(tf.reduce_max(a))\n",
    "print(tf.argmax(a))\n",
    "print(tf.nn.softmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360ca8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e67ef26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
